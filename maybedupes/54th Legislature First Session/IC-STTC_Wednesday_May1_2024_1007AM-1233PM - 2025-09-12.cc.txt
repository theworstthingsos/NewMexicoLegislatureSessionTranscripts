The person doing that is doing
well. The car?
That's her emeritus.
Hm?
My name is Peter Mantos.
I'm a big
of it.
Rob right?
Everybody does.
Uh, you know, I'm on the side,
not a right
to me. I wish you
I'm not
Where am I going?
I started
the A. I
Out of this house.
Well,
And
without like, I'm the only one
who can do
Right?
Good morning, everyone.
We are ready to begin the first,
uh, organizational meeting of
the science, technology and
Telecommunications Committee.
Can you hear me, OK?
OK, OK, um again. Welcome. Thank
you for being here and we're
gonna start with introductions.
Let's start with, um,
representative.
Good. Thank you, Madam Chair.
Good morning, everyone.
Representative Christine
Chandler from Los Alamos.
Uh, good morning, madam Chair
and committee Senator Michael
Padilla represent the southwest
Quadrant of Beo County, also the
Senate majority whip, 10 years,
chairing or vice chairing this
committee. It's one of my
favorites in the Legislature.
Thank you for having me.
Thank you, Madam. Chair, Senator
E Northwest, Uh, Albuquerque,
Bernal. Leo County also serve as
the members of the comedian.
Senator.
Shared a joy Garrett State rep.
Uh
West side of Albuquerque, home
of Petro here.
Can we get
Mark Edwards with L. I've also
been here for eight years.
Um, welcome. I'm honored to be
the chair of this committee
again. And, um, welcome. So what
I'd like to do is have it
Madam Chair Peter Manto Special
I, Madam Chair members of the
committee. My name is
Have been the first Cabinet
secretary for the Department of
Information Technology
testified. I'm Alice Fordham.
I'm a reporter with K UN M.
Well, great. Thank you all for
being testified for everything,
And we so much appreciate
everything so
I, uh I'm happy to be able to
share uh, some some new end over
the last year or so or last year
before.
And, uh, my intent.
Um, will be a little quiz and
and and and then really talk
about, um, some of you know
where I think we're we're
headed, and I think I'm at your
request is to talk about wiser
to the thank you to the vice
president for research at UN M
for a I
Uh, so I've been very involved
in a I efforts over the last few
months. Uh, last night I was in
DC, so I just got back at
midnight, so forgive any slip
ups that might might occur. Uh,
the the Senate was holding an A
I and robotics demo day. Um,
There's just tremendous
excitement around about this
around the state, um at around
the country around the world and
at UN M so
I'm gonna just start, um, with,
uh what we learned from our some
of our colleagues at the defense
contractors bottom line up
front, So I'm just going to put
this up here briefly, and then
we'll talk a lot to to get to,
um, the the Legislature here did
a fantastic job. Uh, passing
legislation last session on
Dake. I think that was an an
important first step to regulate
deep fakes in elections. Um, and
that was it's actually quite
Commendable. I think we we stand
out as a state that was very
proactive in that space, and I
think we did the right thing.
Um, but I think it's a small
step on what's going to be a
very long journey. So I'm gonna
walk through. Um, what Some of
these things are just as an
overview. Um, I think an
important thing to keep in mind
is that, uh, the Legislature
really would, I think Best serve
New Mexico by considering what
to regulate where we need to
rein things in where we need to
protect the population from from
algorithms that might do them
harm and
We need to invest to empower new
Mexican and and I think there's
some really great opportunities
we have here. We have some
opportunities to P. Um so just
to briefly say, I think the on
the regulatory side more on the
deep fake, um, regulation space.
Think there's a lot of need to
talk about health, transparency
and equity. There was a bill. Um
and I think that it's on the
right track, and that is
Uh, creative works and the the
use of creative works in a I is
something that is extremely
important specifically to New
Mexico, where we have such a
large creative population. This
is not exactly my area of
expertise, so I'll talk a bit
about it. And and I just want to
encourage that This is a place
where more work should be done.
Um And I think, uh, another
important thing that was, uh, at
least discussed at the last
session is some form of a study
group. This standing study group
that can really look at what's
coming down the road. What have
you already done? What has been
the impact of
Um
New. Uh, this sorry. There's my
first typo, so new Mexicans
really need a I literacy. I'm
I'm I will give some some
context for that, but I think we
need to get the entire
population up to speed. Um, and
to understand what a I is, um
and I think we are uniquely
positioned to engage diverse
communities rural urban across
ethnic groups across ages in
shaping this A I future. I
actually think there's an
there's an as
Opportunity to really engage the
population. And, um we at UN M
are engaged in work to develop
trustworthy a I that will
advance science and help. Uh,
advance societal goals.
And, uh, we've been engaged in
some partnerships across. Uh, UN
M, other colleges and MS U in
particular we're going to bring
in New Mexico Tech. Um and the
national labs, India and Los
Alamos. Um, we've been having a
lot of discussions about how we
can partner in that.
Um I will say that there have
been some I would say almost
cartoonist, cartoonishly large
investments by industry in a I
over the last months and years
or so, um, it is hard to predict
where that is going. Um
And this is a place where we
have to sort of figure out what
is the niche for for New Mexico?
Um, I don't imagine we're going
to be keeping up with the $40
billion investment that the
government of Saudi Arabia just
announced a few months ago, But
we should think about what is
our our role in this. So, um
I'll do a little refresher,
followed by the little quiz. Um,
tell you some of the things
going on at UN M. That's really
exciting. A lot of it. I didn't
know about until very recently,
um, where to expect. We're going
and then so
Oops. I'm not able to load
video. That's a oh, I probably
am not actually online to the
Internet. Go, OK?
So, um, this you've seen before.
This is, um, a a video of a A
swarm robotics programming
competition that we ran here in
New Mexico. Um, this is actually
a video of the winning team by
sippy, uh, Southwest Indian
Polytechnic Institute That was
in 2018. In total. We had 1500
students participating in this
and by the folks at Sippy, um
and the point of that, uh,
project was to test bio inspired
algorithms. So these are
Algorithms informed by the way
that ants collect seeds and
return them to their nest, and I
actually think this is an
important aspect of artificial
intelligence. It's not just
human intelligence in our brains
that that leads to great things
in the world. There's a lot of
my research career and my lab
around.
Um, another example.
Oops of that.
Is, uh we have, uh, we
Develop, right? Uh, we take to
the skies. We develops flocks of
of drones. We've been flying
those through volcanoes around
the world. This um We're lucky
enough to have a volcano right
here in New Mexico, where we do
a lot of our testing of the V
Caldera, So I'm really excited
about the potential to use a I
and we do use in some cases a I
as as a tool to augment our
science. Um and
Through that we've We've done a
lot of modeling. I've talked to
you about this before of of
diseases and covid in
particular, and one thing that's
given us access to is
understanding where a I is
really a useful tool for places
where people thought. Oh, you
know, the radiologists are all
gonna lose their jobs because
the A I will take over and
that's actually not happened
yet. It still could, but it
seems much more likely following
this space that a I is just a
tool that helps radiologists do
their job better. Um, and it
hasn't really gotten to the
point of Repla.
Radiologists. It's gotten to the
point of augment
So, um
I will just highlight
Um, why There is so much
excitement and you know, there's
a lot of talk about a I in
industry and in government.
Some of it really is hype, and
some of it really is real. And
so what I want to do today is
have you all, uh, hold two
completely contradictory
thoughts in your head at the
same time. Um, because that's
sort of where we are with a I.
It is it is capable of amazing
achievements in science. Um, the
one that I like to talk about
most is Alpha fold, Right? So
this was several years ago, the
ability to predict how proteins
will fold. So this is hundreds
and hundreds worth of work. You
know, in hours
Astounding work that now has led
to new designs of drugs. Um
there's a real crisis in the
development of antibiotics,
right? We have antibiotic
resistant bacteria, and we need
new antibiotics. There been
several papers coming out
lately where a I has discovered
what are potentially new life
saving antibiotics, which
It's not absolutely certain that
those will work yet. But these
are early days and having these
candidates you know, out of all
of the you know millions of
potential antibiotics to have a
I help us narrow down on who a
handful that we can do.
Laboratory studies on this is
all of the reasons why these are
promising that some of these
have done initial studies in
mice and things like that.
If we could invent new
antibiotics using a I That is a
total game changer. You know,
for humanity. We're talking
about saving millions and
millions of lives so absolutely
astounding Technology. Um,
that's an assistant to
scientists.
Um, this particular headline is
about building better batteries,
But I think more generally a I
is very useful at identifying
new materials that can replace
old materials that have
problems. So we have a plastic
problem, right. We produce too
much plastic, and we can't
figure it out how to keep it out
of the oceans, and we have
microplastics in the waters. It
would be great if we could come
up with new biodegradable
materials. New materials that
can be extracted with less
environmental cost. Um so I and
recy
In more in more thorough ways.
So all of these are places where
I think a I has tremendous
potential, and we absolutely
don't want regulation to squash
that.
On the other hand.
Uh, I've frequently talked
about, uh, joy Bei's work about
coded bias, and this was really,
I think, exemplifies a whole
host of problems with a I
Um, that currently, um
Uh, well, this was a seven or
eight years ago that she put her
face in front of a camera. The
camera did not recognize her as
human until she moved the human
being so obviously, you know,
recognizing a white plastic base
rather than her own actual face
as human is an extraordinary
Uh uh, Example of bias in a I
The, um what's most upsetting to
me about this particular case
now is there has been a lot of
work to improve the particular
models that were being used at
the time they now recognize her
face. However, most other models
that she did not directly test
still have these problems.
So recognizing the problem is
not enough to fix it. And I
think that's something, um, that
we really have to keep in mind,
Sometimes in the in the research
world, we think. Oh, we've
identified the problem. We now
we now know what the path is to
fix the problem, but if there's
no economic incentive or no
regulatory incentive for people
to do better
Often they don't
Um, And so this remains a
problem. Um, it's leading, um,
you know, to things like false
false arrests, if leading to
people being, um in in other
domains, you know, outside of
facial recognition, right people
being denied benefits People,
um, being denied jobs. Um, this
is particularly problematic. I
think in that employment hiring
software right where you might
submit a video interview. It's
analyzed by a I that has its own
history of bias.
On what they are looking for in
employees. Um and it then gives
an answer with no explanation to
the employer.
Um, about whether, um and so
this is something that's going
on now, Um, and it's using these
sorts of algorithms that I'll
talk about now. No one knows how
they work often. When they are
tested. They don't make any
sense. And this is a completely
unregulated space.
Um, So this is in the category
of, you know, decision making
tools that are affecting the
everyday lives of new Mexicans.
Um, this is really outside of
software that's used is how do
we want to to write one private
companies were using these to
consider
Um I also very much concerned
about the sort of need for a I
to have more data means that it
is promoting surveillance right?
There's huge economic incentives
for companies to gather up our
data.
So those incentives were already
there. But now what the
companies need more than
anything is more data. And so
there's there's just tremendous
incentive for the data that we
enter to be associated with us
to be combined with other data
so that companies uh veneer of
the idea that they and so I do
think that that being, um
Aware of really is promoting
more general population.
Um and as I'll talk about, uh
there's an interesting
concentration of power in the A.
I domain.
So there are about four large
companies that really have the
computational power to drive.
the next generation of a I is
currently, um out there and, um
it's very hard for smaller
players actually to produce a
competitive, vibrant, um,
economic ecosystem in a I
Um
The
Probably scariest, immediate
effect is related to the idea of
defects that we talked that you
all are very familiar with. Um,
but I wanted to highlight this
particular case of a finance
worker.
In Hong Kong. This is a
sophisticated human being and
who was a banker who was
convinced on a zoom call.
That were that he should
transfer $25 million to 15 bank
accounts.
He got an initial email. He was
suspicious of this email that he
needed to transfer.
He then?
Got a message from what he
thought was his CIO.
Uh, saying, you know, you need
to hop on the zoom call. We need
to take care of this as an
emergency. He hopped on the zoom
call. He saw the CIO and several
Members of his company, who he
recognized
Who told him that this was
important and he needed to do it
believed them. He did it
quickly. It was an entire week
later that he checked to see
what happened. He was so duped
that he didn't know for a week
that he had been duped by deep
fakes videos of his colleagues
telling him to do this.
So this isn't a This is an
astonishing, sophisticated
network with, uh, they believe
had happened was that the I DS
of these individuals were stolen
and they showed up in a
database. So then the database
had these images and it could
then create realistic, least
realistic enough to convince you
on zoom right, So zoom is always
glitchy. Or always some pauses.
Uh, the quality might not be so
high. That's not suspicious, And
so the scammers took advantage
of that.
So you can imagine if this
fairly tech savvy, sophisticated
banker can be fooled by this
What's going to happen to all of
our grandparents?
Right there is there are, uh I
have not seen an official study,
but certainly there are lots of
anecdotal reports of people
getting phone calls. You know,
you used to get a text message
or something like that. Now you
can get a phone call right in
your nephew's voice saying I'm
in jail. I'm in trouble. Please
send money like this. I need a
gift card of maybe it's just
$500 right. Please send that.
I and I, It's actually pretty
difficult, but I think that this
deep fake issue, um goes far
beyond election questions. Um,
here because it does not look so
far like we're gonna really have
much federal protection in the
Um
I gave you this example When I I
think I spoke before.
Of the amazing coding ability of
of this software, so I'm gonna
slightly change my so I have a
lot of evolved perspectives on
this. Um, so I given this
example it's a It's a little
coding assignment that
essentially you have to create
this graph out of and it's a
page of of code. But it's fairly
sophisticated. You have to
understand the relationships
between variables and there are
a few things that lots of ways
to trip up and get this wrong.
Um, and, uh over the years. Uh,
the GPT software versions got
better and better at it until it
was certainly better than
Students and probably better
than just perfect immediate in
seconds. Answer to this
question.
I have been concerned about chat
GPT ability to do my student
students home. I'm still very
concerned about its ability to
do the homework of our freshmen
and sophomores who really need
to learn some of the basics. But
now I tell my students to use
these tools. I expect that they
will use them, and their job is
to figure out how to augment
these tools with their own human
skills. And I have to say I have
never had such joy. Grading my
students papers as when they had
some assistance from chat CPT to
make their ideas more clear.
And I have the students explain
exactly how they use the tools.
I actually validate their
explanation, and their job is
actually to figure out how to
use tools that are out there.
That's a lot of what computer
scientists do.
Um, we no longer program in
punch cards.
Right. We don't have to use
assembly programming right? We
have higher and higher levels of
of code that we use. And now
we've gotten to the place that a
lot of coding can be done in
natural language. Using the
assistance of these, um it's a
great tool.
There is a difference between
all of the other tools and this
tool and then is it this tool is
often wrong.
And it's very hard to detect
when the tool is wrong.
And so what? The students at
this point need to know is how
do I use this tool and be able
to detect when it's wrong? And
we'll talk about how detect why
it's particularly hard to detect
when it's wrong.
Um, but I do think that we need
to figure out how to empower our
students to use the tools that
are out there. They're not going
anywhere. Um, I think we
sometimes talk about
inevitability in in technology.
Um, it's not that it's
inevitable. It's not that we
can't shape the future. But I
think
It is inevitable that the tools
are not OK, so
Um
Last little part of, uh this
This is the reminder of how this
technology works.
Um And I think the graphic there
which is one of my favorite ones
that chay PT created using Dali
for me, Um, the little graphic
of the robot sitting on a pile
of books is essentially how this
technology works. It is reading.
A publicly available sometimes
not publicly available. Digital
text on the Internet.
And it is just learning to
predict what is the most likely
next word.
If I start if I am talking to
you about a I and I'm saying
these sentences, your brain is
actually doing the same thing.
You're sort of predicting what
word? Am I going to say? Next?
Right? And you? You're filling
in those blanks. It's doing the
same sort of thing.
Um, but it's trained on many
orders of magnitude more data.
And so it doesn't actually have
any connection to the real
world. It is simply a pattern
matching machine.
Um it is trained on billions of
these nodes in a neural network.
There are trillions of numbers
governing the relationships
between these nodes in the in
the neural network.
And, um, at this point,
trillions of words right that
has ingested in order to predict
what is a plausible likely
answer to a question.
And the underlying math is fun
and really interesting. The idea
that you could pre re represent
words as vectors so that you can
then perform mathematical
operations on those words, so
you don't just have to read.
What is the next word? You can
also find analogies, essentially
and you can find all the text
that might fill in the next
sentence and understand that
there's a word or there's a
relationship among all the words
that might fill in the next
sentence. Um, there's a little
diagram down there in the
corner, um, of of relationship.
King is to Queen as man is to
woman.
So that's a really interesting
example. Right? We all get why
those would have some sort of
parallel relationship. Um
There's also all kinds of
subtlety in there, so right we
we have assumptions about gender
or even the gender is the thing
that should matter in
determining whether one is the
king or the Queen. And how much
power one has whether one is the
king or the queen might differ
among countries and there might
be all sorts of interesting
dynamics that are sort of hidden
under the relationships that
cause those words to be to
appear, Um
And sometimes it has gotten
wrong. I'd give you this example
before of the word bank that
could refer to piggy bank or the
bank of a river or the banking
of a plane. And so the real
breakthrough, I think the most
interesting breakthrough that
happened in large language
models was figuring out how to
take the context of the
sentence, or even maybe the
entire
Page or book in order to figure
out which word was actually
meant.
Um
And so
One of the things that's
interesting about a I is that it
comes up with plausible not just
the most likely but almost
always a plausible explanation
for what the next word would be,
and that plausibility is why it
is so hard to detect errors
because the errors look right.
They look like things that could
be. That's what it's really good
at is finding something that
could be right. Um, but in fact
is wrong. So if you someone asks
you to, you know, read through
some text and it's clearly
wrong. You can identify the
error you read through, You know
a I generated text and you
Can't tell what's wrong without
really thinking about it. Um and
people, you know, get bored and
lose focus. And so, um
OK?
Here's the quiz part.
Uh, so I actually I think it is
where I This is a fun example.
Um, I gave this in my class. Um,
this was something someone
posted on Twitter a month or so
ago.
If you choose an answer to this
question at random, what is the
chance that you will be correct?
OK, I want you all to think
about this. So I'm giving you a
quiz and you've got to answer
this and you're going to have
real points and your real great
at the end of the semester is
going to depend on it. Uh, your
options are 25%.
0% 50% or 25%.
And you are asked to give an
answer to this question.
So I won't actually unless
anyone wants to volunteer and
answer
I have. I have a 50%. I have a
50% Does any
Final answer. Very good. Does
anyone wanna like offer a
lifeline? Anyone have a
different opinion that the
answer might be 50%?
Well, this is the question as
it's posed. So you choose an
answer. It sort of suggests that
you need to choose one answer to
this question.
And you need to provide an
answer, and 50% is a
Reasonable answer.
You might start to see reasons
why it might not be right. So I
gave this, uh to my class.
A class. It was actually
studying the reason that this is
a problem and about half of the
students. Um, answered, as, uh
Mister Edwards did 50% is not a
bad answer. And in fact, GP T
three.
We'll give that answer. The
right answer is 50%, and it will
explain it's because, well, the
answer is 25%. But that's there
twice, however. G BT four.
Gives a better answer.
In fact, a better answer than my
students and I came up with
after about half an hour of
discussion. And so I'm gonna
read through this answer because
it really indicates why this
technology but really the
strengths here.
This is a classic self
referential question. That leads
to a paradox. If you try to
answer it directly, So this
isn't a class of students where
we have been studying self
reference and its role in, uh,
as the percentages provide
conflict with each other.
So we sort of had a hint of
that. Let's break down the
options if we assume a 25% is
correct, which is where everyone
starts.
Um, there are two options that
suggest this, uh this would mean
there's actually a 50% chance of
picking one of the two answers.
Kurt by chance.
But a 50% correct answer is not
25% right? So that's in con. In
contrast,
But it goes on. OK, so maybe
there's not an answer, right? We
can't be 25%. It can't be 50%.
If 0% is assumed correct, it
implies that none of the answers
provided would be correct,
including the answer B itself,
which is 0%. So again, there's a
contradiction.
Swing, See 50% would be in.
There are two options out of
four that are correct. Which is
not the case. Um
Because, uh, other than the A
and D right so you can't answer
50%. That's just you only have a
25% chance of getting that
correct.
Um 20, then an, and it says that
the question is designed to be
paradoxical and doesn't have a
straightforward answer within
the confines of its own logic.
It serves as a playful brain
teaser rather than OK, I think
Is anyone not impressed with
that? As an answer, I think it's
an astonishingly good,
astonishingly good answer.
If anyone thinks that that I
should give anything other than
a plus for this answer, let me
know there's some. There's
Mark you, you, you
Edwin still likes his answer.
OK, well, it was set up to
tricky right to be tricky. So
there is actually no correct
answer, But I am impressed with
in. His answer is that it
recognizes that
And I shouldn't use the word
recognize large language models
do not have the ability to
recognize they do not think they
are not. They do not have human
agency, but it mimics the act of
recognition in an incredibly
insightful way.
Um
It also, uh, you know the answer
because GPT three gave the the
earlier version of this
software, um, gave the answer of
50%, which is what most people
after they think about it for a
few minutes will say that's sort
of my best. Guess if I had to
pick one, I would go with that.
Um, but not only is this an
improvement and as far as we can
tell it's not because it's seen
this question before.
Um, when you ask it, why it did
this? It refers to all of the
other kinds of paradoxical
questions. It's seen. It's
making an analogy between this
and those other questions. It's
identifying that it's trying to
be tricked, and in fact, there's
a number of cases where people
have given difficult questions
to these language models, and it
will reply. I can tell you're
testing me because this is the
kind of question people ask when
I'm being tested.
That
Now there's there's sort of a
double edged sword. There it is
W it is appearing to recognize
it's appearing to have this
depth of insight. But again,
it's just because it's seen so
many examples.
And so there's a very, very fine
line between understanding
something.
And essentially extrapolating
patterns from lots of answers.
And honestly, I think we do not
know if intelligence is much
more than extrapolating from a
lot of answers. Um, but this is
why it's very tricky to have
people interact with these
machines and understand they are
still just machines.
Um, they do not really have the
same kind of mental reasoning
that we do even though when you
interact with them, they appear
to so they mimic human
intelligence. They have some
other sort of thing, which you
might call machine intelligence.
and it's not the same. And so
when we try to predict what they
will do and where they will make
mistakes, we assume things about
them as though they are human,
and they just simply are not.
OK?
So to switch to, uh so so not
bad on the quiz.
Ah, so I wanna just switch to
what I think has become the big
question about a I, um in this
era, and that is, um
At least to me. The question of
is this going to keep going?
And that is often posed in
Silicon Valley. As the question
is scale all you need
Do we know how to right if we
take these models, and we just
make them a larger and larger
will we continue to improve
these will we get better and
better answers like we did to
that quiz question. Will we get,
um more?
Uh, when we get less, you know,
just made up answers, and the
tech industry has suggested that
yes, scale is all we need.
And, um, here are some reasons
to expect that so these graphs,
I I'll have a couple of these,
um, writer showing, right? I
think I talked to you about
these before. Right? These are
billions of parameters over the
last few years going from, you
know, less than a billion up to
hundreds of billions of
parameters governing these
models, then uh, this big bar is
Cheetah GP T four Again. Orders
of magnitude increase in size.
Um, so that these models are
just a so enormous that they
have scraped up.
A large fraction of the data on
the Internet. There's not that
much left. Um this feeds back to
the idea of surveillance if
these companies need more data,
they have to extract it from us.
Um, and so that's a real concern
that they have economic
incentives to do this.
By scraping all of these data.
This is, um a bit of a messy
graph, but our world and data
has these, uh, all kinds of ways
to play. Uh, late nineties to
now, this is performance on
benchmark tests, so things like
law and math and reasoning. Um,
The zero line is human
performance and all of these
tools as they got bigger and
bigger began to surpass human
performance.
And so this really is, you know,
an astonishing result that you
can surpass human, um
Even so.
It still manages to be wrong. It
manages to be wrong in ways that
are less obvious. So in some
ways, this is actually a decline
in what we want the tools to do
because they are getting better
at being plausible faster than
they are getting better at being
right.
Um
This is another, uh, version of
this. This is from, um Rick
Stevens at Argonne National Lab.
This is just from 2011 to 2022.
So this is back in the days of
Watson. If people remember
Watson, right, that did well on
jeopardy, right? And this is
saying we have gone from 10 to
the 14 to 10 to the 24 flops. So
10 orders of magnitude. So you
know many billions of times
larger models trained to get to
these results. I really was not
happy with any of these graphs.
So I asked Chach BT to create
one and
And suppress it. This is all
made up. These numbers are
completely wrong. Um, it I went
back and forth, it said, sure,
Let me create a visualization.
Hold on. It prepares this figure
in like 30. Seconds on the
airplane last night, Oops. And,
uh
See if I
It did not like my critique at
all.
And it seems to have
disappeared. All right.
So like and my
Let's say I for me. Yeah, I
won't. I'm sorry. Cha G BT. Can
I please have the Internet back?
And let's see if
OK, so that was just a warning
shot.
It's letting me have my slides
back.
And
OK, so
This is just a mild criticism of
G BT, so it will allow me to
continue. Um so it's made up
data, and it has these Here's
there's some tells. It just
says, Like, what am I comparing
here? Just says Log scale units,
right? It's talking about these
different models, it says GP T
three, and T four. Lama has many
different versions. It doesn't
say which one it is. It's just
completely made up all of this
data right when, um, here it's
pretty obvious that it's making
it up. Um it's pretty obvious
that it's making a point that
these things are getting bigger
over time. But
It's just this is just another
example of its lack of reliance.
Um, I think an important thing
to keep in mind when thinking
about the idea that all we need
to do is get bigger and faster.
Is that the companies that have
the what are called Frontier
models now are the only entities
that can make these models
bigger and faster so if they can
define the game as get bigger,
faster, they automatically win
because nobody else can play.
Um And I do think that this has
had a really pernicious effect
on how we think about these
models. I think that there are
alternatives. There are people
working on alternatives. But
when you have Microsoft claiming
that they're gonna build $100
billion supercomputer in the
next few years, because this is
what you need in order to
compete in this space. It means
they get all of the investment
right to drive. Um, so this is
about Saudi Arabia. Arabia? Uh,
I think, uh, Qatar, There was
some announcement for about
Uh, an a I center in Dubai of
this sort of scale. Um
And to put this in context. Uh,
so Los Alamos just had a really
nice large supercomputer
installed. Uh, NATO.
This was a is a 3000.
Poor machine. Um, for comparison
at UN M we've got about 70
cores. 70 GP U cores 3000 core
machine. This is really
impressive. They are going to do
great scientific work with this.
Facebook already has a 24,000
core machine.
Um, which is not enough to train
its recent models called llama
It actually had to curtail its
training of some of the models
in order to have space and time
to train the larger ones, right
and they've got an order of
magnitude more compute, um than
this new computer at Los Alamos.
The, um this $100 billion
supercomputer would be orders of
magnitude. More computing power
is not for free, right so well,
it's so it's a It's a real It's
a real money maker for NVIDIA
That makes these course. Um,
it's a real moneymaker for these
companies that host these A I
services because they also make
money on running them. So now
that they even when you get some
of the models for free you
someone is then paying for the
cloud. Um
So this is sort of the direction
the industry is incentivized to
go.
And I think it's really
important to remember that the
rest of us don't necessarily
have to be incentivized to go
only in this direction.
Um, And that's some of the
research on, um
This is just another. This is
from The New York Times A couple
of days ago, Microsoft, Meta and
Google
Spent $32 billion combined on
data centers in the first three
months of this year.
This is astronomical amounts of
investment just based on the bet
that someone is going to have a
really big model that really
outpaces the existing models,
and they will then make
billionaire
Um
An important thing to note is
that people had been saying, Oh,
we were expecting this
technology these capabilities to
double you know, every few
months, maybe once a year.
Um, It is noteworthy that when I
was here before I was talking
about GPT four as the best model
GP T four is still the best
model. There are other ones who
have gotten gotten close and
people maybe will argue about
certain other models that are
are a little bit better in
certain domains. But nothing has
made the kind of leap that
happened between GPT three and
GP T four.
It really seems like there's
been a stall. Um, it's possible
that the next GP T five will in
fact be a big improvement, but
it will be a big improvement
that took way longer to get to
than the previous one. So we're
already seeing a lot of evidence
of, um
There. I think that most of the
interesting work lots of small
language models were. That's
something that, um will come
here.
OK, so we got here largely from
scale.
We got here from a few clever
tricks that neural networks have
have.
Have been added to neural
networks that are basically the
same architecture that we've had
for 50 years. Um, but now scaled
up to this massive size. Um
Human feedback is really
important in these models in
order to know they did something
wrong. Some human has to tell
them. The company used to go to
Kenya and India and places
around the world and pay low
paid workers to just tell them.
Yes, no, This is good, bad to
strip out all of the terrible
violent porno pornographic
material on these tools. Um
Now we all do that for them.
Every time we use these tools,
they have ways to learn what we
liked and what we didn't like.
And that, um and so they have
this ability to use our feedback
to improve the tools And I think
that that will, um I talked
about the market and in an
economic incentives that have
concentrated really the power to
build these models in a few
companies. I do think there's a
really exciting moment where
smaller models universities,
national labs, places like that
can find ways to build models
that are sort of in the in not
just for profit, but for you
know, public good.
Advancing science, Um
And and then, of course, there's
models, um, either the large
models or many small models
going forward. So, um
Switch gears now and talk about
some of the work that we're
doing at un M. Some of this is
in collaboration with other
places in the state, but I
wanted to highlight, um
Couple of of different things.
So this was sort of a survey of
a I research happening at UNM. I
had no idea I found 30
colleagues doing research in a I
just on main campus, so this is
not even in Health sciences
center.
Um
People are working toward, you
know, smart water allocation set
solar energy generation and
storage. Forest fire mitigation.
Um Everyone who has a scientific
problem essentially is now
looking. Can IA I help me? Do
you know do my work better?
Um And these are all places
where I think we are really well
positioned to keep going. So,
uh, there are lots of us who are
thinking about how do we build a
secure infrastructure so we can
have trustworthy a I whether
it's for medicine or law and
policy. Um, education national.
Certainly there are lots of
advances in the high tech end of
biomedical work. But
additionally, drug discovery
personalized health care, um
And and thinking about how do we
serve the population of our
state?
Um
Novel materials. We mentioned
that, um all kinds of creative
work in computational
fabrication. How do synthesizing
data? Um, for environmental
monitoring? We do things in
earthquake and or in in volcano
model. Modeling. Uh, lots of
folks are doing earthquake
detection and methane leak.
Identification. Um, is big here.
Los Alamos is leading some
efforts.
This, uh, bullet developing new
open source foundational
architectures. So right now, uh
there's llama is an open source
model. They don't tell you what
data they trained on. But they
do provide you a model You can
Bring into your own
organization, and you can, uh
increase the, um
And and and you can use your own
data locally, so you don't have
to give them all your data to
use the model itself to do
predict good stuff for privacy.
Um, but most of the models don't
allow you to do that. We really
think that we need more
competition in sort of the
energy aware A I is extremely
important. These these huge data
centers, um, are just they can't
find places to put them. There
is no state that will say we can
offer you enough power and
enough water to cool this data
center that you can put it here.
I mean, it's uh, this is really
one of the limits is we just
don't have the power to actually
drive these. It's expected that
10% of the electricity in the
United States will soon go to
powering these A. I models right
and an era of climate change.
That is an astonishing and
really not a a future. We want
to go to right. We're making
progress right in green energy,
And if we suck up all that
progress into training a I
models that's not a win.
On the other hand, if we can use
a I to develop new green
materials and new recycling and
things like that, then there
could be a win there, but it
really depends on how we drive
this technology.
Um, I don't think that the win
is to build these giant data
centers. I think the win is to
figure out other approaches
that, um, we need
Um, in terms of fostering, uh,
collaboration and economic
growth. I really think we're at
a point Where you, uh, where?
Where New Mexico as a whole can
be a high performance and a I
technology hub. The national
Labs really are big players. Um,
in this, they always have been
Um we are working now to
collaborate with them and
establishing some some MOU so
that we can share scientific
insights. We can share computing
power. Um, we can attract world
class faculty and and industry
to the state.
Um And so we were really, really
working on. How do we spur a
start up ecosystem to drive some
economic innovation? Um, some of
this, uh, we hope will follow
the quantum, um, initiatives
that we have with the labs.
Um
I particularly wanna highlight
that we have a our diverse
population here really is a
resource.
A lot of what a I is doing is
shaping a future with a limited
kind of data, right. So like
joy, Bu Andi's face, the more
faces you have right in your
training data, the better job
you do in understanding the
world. Um, I really think we
have some opportunities to
engage in particular K through
12. Children engaged rural
populations. Everyone in the
state to say, what do we want
this a I to do.
Um
So let me um, kind of get to
that. So you've seen this
picture of our interdisciplinary
group and algorithmic justice.
So these are some of the sort of
human resources we have in the
state. Um, this is another
group, uh, all at UN M in
computer science and E CE that
are developing trustworthy
platforms. Some of this is
highly technical and
mathematical work. Some of this
is testing it on medical and
legal data.
Um
We are and this sort of
highlights some, uh, some of the
theme. Um so there's a lot going
on here that I think can
Go through these quickly
catalyze this kind of work. Uh,
just a couple of weeks ago we
had presentations by faculty
across arts and sciences. Um, so
these are people in psychology
and political science and earth
and planetary science who are
looking at machine learning for
brain science and machine
learning to go through
government texts and understand
what government you know for
government accountability and
understanding, political
polarization and how a I may or
may not be driving lots of work
and an earth and planetary
science and environmental
monitoring. Where's using
There was a great presentation,
uh by by Chris, Uh, Lippitt, who
is using a I, um to monitor how
populations of wild animals are
moving, Um in response to
climate change and shifts in
precipitation. Um, he had some
great examples of how IA I was
much better at identifying a
duck from a satellite scientist.
Right? So these are great uses
of these tools, um, that I think
really will help to advance us
as a state and we do need to
find ways to collaborate. Um, I
think as a I think I showed you
this before, And I think this
this
Rings true to me more and more.
Um, this quote from Oppenheimer.
We thought we might start a
chain reaction that might
destroy the entire world.
Luckily, they did not right. We
did not burn up the entire
Earth's atmosphere with a F. You
know, with the Trinity test.
Um, but we do. We are still
living with the ripple effects.
We still right. We still have
technology out there. That
really could still destroy us.
All right, and we've built up in
a tremendous amount of
infrastructure to keep that in
check.
Um
Uh, a I and many people think
threatens some of that
infrastructure that we have to
keep that in check.
Um, but the point is that when
we have a radically new tech
technology, we really are
terrible at predicting what will
happen.
Right. Our worst fears are
usually not met, Um some other
really negative consequences are
entirely unanticipated and some
great consequences are entirely
unanticipated, and I think
that's where we are now.
Um
Uh, I, uh, So even in the case
of deep fakes, which again I am
in favor of and he did a great
job regulating defects in the
case of defects there are uses
of defects that are fun and
interesting. Um, it looks like
the video won't play. Uh, but
you can go. Uh, click on this.
this link and you will be able
to see the lobster phone. The
lobster phone is a telephone in
the Dali Museum. Where if you
pick up this phone that looks
like the handle is a lobster.
You can have a conversation with
Dali and he will explain his art
to you in his voice.
And it's very entertaining, and
it's clearly it's using the same
deep fake technology. It's using
old recordings of his videos and
his voice. So it feels like
you're having an interactive
conversation with him. Everyone
using this understands you are
not actually talking to Dali,
but it's a great educational
tool to help people really
interact with right this time
with with his work. Um I don't
think it's worth it. I think
that this positive use case does
not outweigh you know the
robocalls of your of of, uh that
that we've heard.
Political campaigns, but it is
worth keeping in mind right.
There are good and bad uses of
every technology.
Um
The, uh the thing that I think
is most important for us to do
is whatever role we play in
regulating a I that what we are
doing is engaging the population
in that regulation.
And so, uh, this is, um John
Powell.
Who, uh, told the story and I
really inspiring to me, uh, that
during the space race, he went
to one of the space centers to
talk to Kennedy.
And as he went in, he met a a
gentleman who was cleaning the
floors and he introduced
himself. And he said, I'm John
Powell. I'm here to help.
Uh, Kennedy get to the moon and
the janitor replied with his
name, and he said, I'm the
janitor and I, uh also, I clean
the floors here.
And I'm also helping America.
Get to the moon.
And that is a sense that I think
we have all lost right that we
all matter that it's really not
just a few companies running
this software that matter and a
I is absolutely the perfect
place for us all to understand.
All of us are important.
Right? A. I is fed with the data
of most of humanity, not equally
right, And it's not really all
of our knowledge, but it's a
pretty good slice of a lot of
our knowledge. We really have
shaped, uh, made this po this
this technology possible. We
need to figure out how to have
people shape how it's used
right. We cannot have a
situation where all of humanity
feeds their understanding of the
world into these tools. And then
three or four companies take
that knowledge and decide how it
will and won't be used. Um so
government plays a really
Important role here.
In figuring out both in sort of,
you know a regulatory side of
this, but also helping to figure
out how do we get people
involved in training these tools
and I'll give one example as we
talked, Uh, through this, Um
Meat of this last slide.
Uh, one example that I've heard
of that's happening at UNM, uh,
at at the hospital is that
doctors will use uh
GP T or other large language
models to figure out how do I
Uh, explain a very complicated
medical procedure to someone who
maybe has 1/9 or 10th grade
education.
I'm using really complex high
tech terms. That's the word I
use. Uh, the world I live in,
but I need them to understand
that this can actually save
their life.
And usually when the doctors use
these sort of, you know, you
know these ridiculously
difficult Uh uh, terms for
people to understand people's
reaction is I just don't want
that. I don't trust it.
And now they use these tools to
just translate the language into
a language that people can
understand.
And there could be some people
sort of have the reaction. Oh,
is this the the A. I sort of
convincing people to do things
they don't want to do. I don't
actually think in this use case
it is. I think it's putting
things in terms that people can
understand. And I think that's
an admirable good use of these
tools for people to be able to
communicate better for these
tools to sort of act as a
bridge.
On the other hand, it would be
great if instead of the doctor
and somebody at open a I
deciding what is the right way
to talk to this patient. We had
data from diverse communities
all around the state and the
world, saying this is actually
the kind of maybe I'm refusing
this procedure, Not because I
don't understand your
terminology, but because I think
you didn't hear me, right? I
think you didn't listen. So
maybe what we need is the
conversation to flow more like
this.
And we actually have. You know
if we have, um
Opportunities in classrooms, for
example, for people to engage in
telling, you know their
teachers but also telling these
models, this is how I want to
communicate. This is what I want
to know This is the kind of
things I don't understand that's
actually possible. I mean the
power of a large language model
is it is a human accessible
interface, and we can make it
far more accessible to engaging
in, um you know, community
centers and K through 12 schools
and places where people are to
ask them. What
Um, And so that's an experiment.
I think that that is worth
trying, right? Can people help
to shape how this what it is
used for, um so that those
decisions are really
democratized.
Um, to make that happen. Um, New
Mexico, you know, right? We need
a I literacy. People need to
understand what the tools are.
Um, There's a great program that
Irene Lee runs. Um, occasional K
through 12 programs. Uh,
everyday A I is a project. Um,
that is now in some of the New
Mexico schools. Um, it's also
around the country.
We need to, um so a I. Literacy
is sort of the first step.
Uh, a data point. I just
recently heard an estimate of
the number of undergraduates at
Stanford, who take a computer
science class is approximately
95%.
Um, evidently, more students
take a computer science class,
then their core required courses
for graduation.
You can get away right? 5% of
the students figure out a way to
get around. Maybe they're
transfer students a figure a way
to get around with the required
courses, But everybody takes a
class in computer science.
At UN M. I believe that is
approximately reversed. We might
have about 5% of our students
who take computer science class.
We just don't have the the
infrastructure. We don't have
the sort of cultural impetus to
to encourage students to do
this. People think it's too
hard. We right, so this is a
place where we really need to
invest in more education. Um it
needs to start in K through 12,
and it needs to continue up
through the through the
undergraduate curriculum.
Um, that's sort of a
prerequisite to engage people in
shaping the future of a I.
They've got to understand what
what A I is.
Um, I've talked. I think here
before you've talked with me and
Chris Moore and Sonya Gibson
Rankin about trustworthy A. I So
there's both the technical you
know. How do you? How do you
build the machine underneath the
interface? Uh, to people. Um,
but what We really I think need
to invest in here is
trustworthy. A I That, um, is
verified, So I think a trust but
verify model is necessary. And
with a I It is really a complex
system. You're not going to be
able to write a, you know,
create a law.
That regulates a I and expect it
to hold for years on end
process, which is why I think
sort of the study group sort of
approach where you're constantly
monitoring. Is this regulation
having the effect of good and
avoiding the bad effects that we
expect?
Um
To go, uh, back to sort of where
a particular investment. Um
Deep fakes beyond elections. I
do think, um, I. I have a slide
here, but I'll I'll just say it.
I think New Mexico really made a
good move with regulating the
use of deeps in elections. Um
and we did so early. I heard,
uh, from Alisa. Lower, uh, that
we were the first state of of
the 30 or so states that we're
considering legislation. Um, in
this last year, we were the
first ones to go. Um, a few
others have followed. Many
others have given up or things
have sort of died on the vine.
Um and I think we have
I start with that, But it really
is just a start. Um, In one
sense, um, I will be bold and
say, Well, you've protected
yourselves right? We protected
people who are running for
election. Um, the rest of the
population also needs this sort
of protection. Um, the the deep
fake pornography problem, right
was popularized by Taylor Swift.
That's a real problem. Real
individuals who don't have ter
Taylor swift numbers of Twitter
followers to protect them really
are seeing, you know, images and
video of themselves out in the
world in
That are absolutely horrible.
There was just, um and another
example a case of, uh uh, sort
of slander where someone had
accused someone of being racist
and they created a clip.
Right of it was a principal in a
high school of them in and you
know, saying something that was
a racist rant just from a deep
fake
Now. I don't know the back story
there. I don't know what you
know. May maybe they were
replicating something the person
already said, But that is a use
of deepfakes right that we We
can't let stand. Um, both for
the particular individual that
is going to suffer, but more
broadly because all of us will
learn to distrust reality. If
these deep fakes proliferate,
and it doesn't take much, and I
think we're already pretty
close, See, which is a really
hard way to run a democracy. So
I think the deep fake, um, issue
is still kind of the
Um, you already have a start at
a A bill looking at Trans this
slide here. Uh, this is an
article that Chris Morris sent
to me last night. Um, arguing
for transparency, audits and
fairness in a I, uh
It argues the devil is in the
details. In these laws, A lot of
states have passed laws that are
full of loopholes.
And so they're not effective.
And so what They really arguing
for is be careful. Don't just
take the mold of what people
have already passed. There are a
lot of loopholes, particularly
around trade secrets. I think
that the state of New Mexico
should take the position of an
algorithm is making a choice
that affects someone's freedom.
Their financial, uh, well being
those sorts of high cons
consequential decisions. There
can't be a loophole that says
This is my trade secret. So I
can't tell you why I'm denying
you this loan or keeping you in
jail or whatever, Um
Of this
If the model is not transparent
and can't be explained, it
shouldn't be used in this kind
of high stakes. The line we can
draw and the kinds of models I'm
talking about. Now these large
language models, they are not
explainable.
There is research attempting to
figure out how to explain it.
But, um, the Explainability
would have to require
Understanding the meaning of
trillions of numbers in that
mesh and an impossible task.
I think that these models are
really ill suited for me. Ah,
the, um
And and enforcement is another
component of this In a lot of
cases. These these these laws
that are out there sort of go
back to a point on the on the
deep fakes. Um, that was made,
Um
Uh, by a recent article, uh, by
Daniel Dennett. He's a
philosopher who was associated
with the Santa Fe Institute, and
he talked about deep fakes as
counterfeit humans.
And he asked, Why do we outlaw
counterfeit money?
Why is it illegal to counterfeit
money? Well, the reason is
because it erodes our trust
Money is based on trust. We all
value we all assume it is what
it is worth because it is real
If you allow counterfeits,
counterfeits, um this completely
erodes trust in the economic
system, and it will collapse.
His argument is if we allow
counterfeit humans, that is a
much worse problem.
That
That faking someone else so that
you can't tell what is real. And
what is not, is just a huge uh
it it it. It destroys the kind
of trust we need, He argues, not
just for for democracy, but for
maintaining a coherent
civilization.
Um so I really think And and
right now, it looks like the
federal government is not moving
super quickly on this, so it's
been left to the state.
Um, I'll just I'm gonna
highlight an article that I
wrote with so Sonia Gibson
Rankin called Medical Artificial
intelligence should do no harm.
Um, and the argument here is
there is tremendous potential in
the biomedical field in
particular and in patient care.
Um, but we do not know ways. Uh,
but but but
We know sort of technological
paths to make this happen, and a
lot of the problem is that
people don't trust these
algorithms. Um, and the
algorithms aren't trusted
because they haven't been shown
to be trustworthy and so
trustworthiness in the
algorithms and in the underlying
systems that they are. The
interfaces for are really key.
We can't really have trustworthy
medical. A I without a trust Me,
OK, mine is without a
trustworthy medical system.
Um, Last slide, I will mention
is just a way of thinking about
this. I I'll leave the link
there. Um, a paper from, uh uh,
that just came out a couple
yesterday. I believe, um, on
complexity and a I That suggests
again that the real issues here
are how do we these what of
humans with these different
machines with the data from the
past and what we're trying to do
in the future? Um, and that we
have to look at I will leave it
there. Um, there's some
resources.
Thank you
One of the things that Madam
chair you know, a I obviously
Something faculty working in a
IA I There we go. We're gonna
use it to have some good fact.
They are.
I'm confused. We need to call a
I OK.
Thank you, Madam. Chair Senator
Rodriguez. So excellent
question. Yes. Um, And I think
this is an illustrative example
of what you can do, Uh, that
mimics sort of the process we
use to try to ensure the
trustworthiness of the final
product. So a I is very good at
making recommendations, as I
said of things that are
plausible.
Things that could work to know
whether those things work. We
have techniques to do that. We
have the scientific method,
right? We have hypothesis met
testing. We have We have
concrete ways that we step
through a hypothesis step by
step to validate. Is this
correct? So when I mentioned you
know antibiotics, right? A. I is
great for recommending this
might be a brand new antibiotic
that can protect from from from
bacteria that are escaping our
current drugs. You don't just go
give that to people, right? You
go through clinical trials.
You does. This, actually, uh is
is actually helpful. Does it
have harms that we didn't
anticipate right and that's a
bit of that is a long process. I
think in science. We're very
good at that. And that's one of
the reasons this tool is so
useful in science.
In policy. I'm not so sure we're
we have that tradition of here's
a policy recommendation that
will make the world better for
people we actually need to test
it.
And as far as I know, the only
way to test it is with small
steps right allow certain things
disallow certain things and then
revisit
And I think that revisiting the
policy choices piece is
something that is is is somewhat
new. Maybe, but could be a real
benefit right to be in the habit
of when we make a regulation for
a I we check to see. Did it have
the intended consequences,
particularly as the as the
technology changes? I do
actually think this is a
research area, I think is, Can
we use a I, um there's some.
There's the idea of adversarial
A I can We use a I when you
proposed legislation to take
care of a problem. Can we ask a
I What
Want you to be an agent that
tries to get around this rule.
Right, like so so so that it
does that and then can tell you
Well, I can anticipate that
these three things might happen.
Maybe you want to close those
loopholes That wouldn't have
been obvious without using these
tools. That's the kind of thing
that I think a study group could
actually enact. Yeah, and it
seems like there was reliable.
And for a thing
Is not necessarily could be good
information, but it's not
necessarily, um
You know, but it's used, I guess
to define that perjury as just a
one sentence response to that is
this is exactly why we need a I
litter in that as the first
step, and it is insufficient. I
think when you read something
false you you believe it, even
though you know it could be
false. So that's not a that's
not a panacea, but it is an
important first step.
Madam Chair. Um, committee
members? I'm representative
Janelle
Yorn
quadrant of the Metro area. I
did not have any for Rodriguez
mentioned. We learned so much
every time you come, and every
time you presented, I'm like I'm
but, um
Good to see you again, Doctor
Moses. So you pick my entry and
What I found and relies on the I
got a little concerned, you
know, so there's trade offs,
right? So here we are. We're
really excited. Los Alamos is
had I assumed then that there's
likelihood that they'll be great
electricity and a large
supercomputing machine in North
so fantastic question. Thank
you, Representative Chandler,
Madam chair. Um so yes, And no.
Um one thing to consider is that
these enormous number
That we're talking about right?
10% of the electricity use in
the United States is from these
incredibly large projected super
computing machines that really
dwarf
This new machine. They have, for
example, at Los Alamos. However,
right we are a state with
limited water in particular, and
so I have not seen an assessment
of you know how much water and
electricity use is there for
these particular machines? It's
a it's a good question. It's a
It's the kind of thing that we
should know the answer to, um
before as part of the decision
making, I think that at these
sorts of scales, they are not so
different from other computing
and other kinds of
infrastructure, But it is
something
Absolutely. We should keep an
eye on. Yeah, And I mean, uh,
thank you, Madam Chair in my
observation. OK, so it's what
What did you say? 3000?
Whatever. 1000 GP US 4000, But
you know they're gonna We're all
gonna be scaling up. We should
assume there's gonna be a scale
up over time at our various
laboratory. And should we be
thinking about requiring some
sort of interaction with
The community. When these things
are being built, we have, uh,
that the resources are there and
they're not going to negatively
involving in a town.
Um So that's 0.1 I, you know, I
also point out to the committee
manager that you know, there's
been talk of putting in another
to the lab and fair amount of
resistance. Um
A A about that for various
reasons, so I just wanted to
alert folks to that that that
had those. It's not just what
some people view as our core
activities. Um, computing is a
big deal, so I just wanna alert
folks to that. Lastly, um
Madam chair. We talk a lot
about, um, you know, validating
the, um tools. The A. I tool
that we have a sense that
there's reliable.
So you and M uses a I
Is there a process in place that
UN M to validate? A. I, um
And I asked that because I was
at a briefing recently and I
asked that question And the
answer I got was, well, um, some
of the stuff is proprietary. So
some of the stuff we can't
validate because it's
proprietary.
And second of all, we rely on
things like OK, So, um
You know what's what's good for
the goose. And I guess we're the
goose and you're the gander.
What are we doing at? Uh, you
know, OK, we get advice from
you. Our our is the university
also pursuing ways to ensure
that a I is being that is
reliable in the way that it's
being used there.
Thank you. Yeah. So thank you
Chair and and, um Madam Chair
and representative Chandler. So
let me start with the second
question, which I think ties.
Uh, back to the question from
Senator Rodriguez. How do we
know that?
Uh, that that a I is valid and I
think
At this moment in time. We have
to make the assumption that it
is not valid.
But lots of things that we do in
research are putting together
hypotheses. So I think of what
a, I suggests is a hypothesis.
It's a plausible answer. It's
something that could be right.
That's where we always start
with research. So to answer this
as a scientist, and then I'll
get to the trickier part, which
is things outside of science.
This is very much what we do
right. We take uncertainty and
we try to validate which parts
of this uncertainty are correct.
Which thing is true, which and
we have lots of techniques to do
that, and we should not rely on
a I
To do that validation.
But it could be a tool to create
some code to analyze some data
that you check very carefully to
make sure the code is doing what
you think the code is doing. And
then you have tests and right.
We're pretty good at coming up
with tests to to validate those
things. So there's some care
that's required. But I think
that in the scientific process
it is part of the S the
uncertainty that we deal with
all the time.
In, uh, secondarily. That is one
of the reasons why trustworthy
A. I is such an important part
of the research that we're
doing. Um, so we are trying to
validate. In fact, when you feed
a data set into this particular
kind of model, you get a true
answer about the correlations
between you know cause of death
and this particular thing that
was in the data, um and we use
other methods to do that, and
you know you use multiple
methods and you use statistical
inference and things like that.
See OK was the A I doing what it
said it did.
Um, some of the research the
more foundational research is,
do we need to redesign neural
networks?
Right the structure of that so
that they work differently so
that they are more reliable so
that you can point to places in
the neural network to say this
is actually the data that drove
this decision to be made. Um
right now. You can't do that,
right? You can't sort of point
to the data, so I think it it
very much depends on the kind of
question that you're asking.
And it is why I think high
stakes decision making that
affect real people in real time
is where it's particularly bad
to just rely on a I so I would
never just rely on a I for a
scientific conclusion, right? It
would be part of many tools that
I would use. I would also not
want to just rely on a I for, um
and so I think that that that's
sort of part of the question. So
you know at UNM, do we ever get
an answer? Because we just fed
something into a I sometimes
right. Sometimes there's
analysis of data on Social
media.
Or something like that. You
might say this is the method I
used. I put it through this
tool. This is the answer I got.
This is an intriguing answer.
The scientific method is almost
never you do this once and then
the answer is settled right?
This has to be repeated by
dozens of people using different
techniques and those sorts of
things.
This is the piece of it that I
think is important to sort of
bring into the policy and legal
community is that these answers
are not you can't just take it
off the shelf and run with it
right?
I don't know if that helps to
get it at your which is
Madam chair. Well, a tiny bit
but not really. Let me try
again. So you come to the
Legislature, you know, with
great advice, and you know I
don't wanna Ah, a great advice
about we should have a law that
we kind of thing Is that what
you and M is doing?
You just went through a great
explanation about how you as a
scientist test the kind of
validity of a I mechanisms, but
There's not just research Yeah,
UN M or other schools. You know,
I'm not picking on
Ah, is something similar being
done there? I think I'm getting
the thank you, representative. I
think I'm getting at the heart
of your question. So most of
what a I is used for at UN M is
research.
Um, it's I don't I'm not aware
of it being used. If anyone is
aware of it, I hope I would love
to chat with people who are
involved to be making these
sorts of high stakes decisions
about people. I don't think we
actually have those use cases be
interesting to know if if we do
places where it is other places
that it's used as an education.
and as I mentioned, right, I I
now encourage students OK, play
with these tools, see how they
work that sort of thing.
So, Yeah. So I'm interested in.
Uh, I'll I'll get your get your
I don't know which use case
you're you're talking about, so
I'd like to hear more in in the
case of education, right? It's
it's see what these tools do, or
almost testing the tools as part
of the educational process to
see how they work, So I think
that's appropriate. Um
I'm but yes, maybe you could
explain. Are there particular
use cases of a I where you think
it is in this sort of high tech?
offline? We can have that
conversation. Thank you, madam
Chair.
Thank you, Madam Chair and thank
you for the presentation. Thanks
for really looking into that in
the future.
Um, also the deep fakes. You
know, every time I even but then
we've seen the more I
Is there anything that we need
to look at? Um in these
antibiotics could work. But
there might be a reason why
they're not out there. Are there
safeguards or barriers already?
You madam Chair, Senator. Pope.
Excellent question. Um
Uh, for the case of antibiotics
in particular. Um so this is
something where right These
tools are making
recommendations. These aren't
exactly large language models,
but it's based on the same
principle. It's looking at
compounds we have out there
already in use for various
things and saying which of these
are plausibly an antibiotic
right? That's sort of the first
step.
Um So you know, you might take
10,000 things and narrow it down
to 100 and say, OK, these are
plausible candidates. Um, then
you might take that 100 say,
Well, let's do some further
analysis on this and the A. I
might be able to do it. Let's
look at chemical structures.
Let's look at how they bind to
different things. Let's look at
interactions. Um, and then that
might narrow it down to 30.
Um, at some point you get to a
place where you say OK, Well,
here are 30 potential
candidates. Now we need to take
this in the laboratory. And we
do the standard science that
we've already that we always do.
And this is where I think your
question is particularly
interesting. Can we rely on the
things that we've always used
when humans have come up with
these candidate drugs to test
them for side effects and
potential harm and efficacy and
all those things can we rely on
those tools the same way when
it's an A I that got us to that
place.
And I actually think that's a
really deep question that we
don't quite know the answer to
because, as I said earlier,
right, the A. I is good at
coming up with plausible things
that are somewhat out of the
box. It is in that sense, I
think quite creative and
creativity can be a little
dangerous. And so I think that's
a question The biomedical
community should ask. Do we need
an additional sort of lens on
this In order to do maybe
additional safety ta testing?
um, in order to trust things
that were originally recommended
that way. Certainly
They? There shouldn't be a
shortcut that says we don't have
to worry about all of the
others, you know, clinical
trials and all the safety
standards and things that we
usually use and I. I think it's
a very good question. Do we need
more? I think that in and of
itself
Is is a research question.
Yeah, And and I think we're you
know, really gonna be thinking
Professor, Um Moses. So you talk
about a I the need for a I 12
you also mentioned And this is
something that a chairwoman
started. But what does a I
literacy? Excellent question. Um
And I would suggest actually,
that that this everyday a I
program that that Irene Lee has
has been, um, beginning to move
through. The state is a good
example of this. It looks like
many things. This is another
place Where experimenting Right.
What is the right way to teach
Children about this?
Technology and what is the right
time to teach them? Which
things? Um
On the technical side. You know,
there's the question, so this is
something we face as I suggested
in computer science, right if
you teach Children how to
program using a I they'll never
learn how to program right. And
so it's the same question of
when do you give a child a
calculator?
Right. You need to learn to do
some basic arithmetic before you
give a child a calculator, and I
think representative Sarana may
have opinions on this right.
They they're good. I think we're
still trying to understand the
consequences of when do you
bring calculators into the
classroom? When do you assume
they know enough basics that now
using this external tool is
helpful and not hindering their
basic understanding of
mathematical concepts. So there
there we we're gonna have to
find that balance, And I don't
think we quite know. Um so
there's a little bit of
experimentation.
There are things on the social
side side that are very
interesting. Um, For example,
how should and on the question
of how should the A I interface
with with Children? Um and, um
Uh, Doctor Lee had some examples
of you know, there were some
sensitivities to particular
kinds of content that say
Hispanic versus Native American
Children would have reactions to
right negative reactions to
certain iconography and imagery
and things like that, so that's
another angle on this right?
What is the right way to
represent things? Um, in this
space? I think most of it is,
uh, that I think the great
advantage of this is it's
encouraging play.
Right. It's very interactive.
It's encouraging students to be
creative. And you've I've I've
seen this in my own students.
I've been seeing this in myself.
I have an idea, but it's sort of
the same idea as you Google
something. And you Google the
next thing but to be able to
have a conversation about a
topic that you're excited about
It really can generate your
interest in the topic. Now
again, there's still this
problem that it might tell you
something wrong. But if you have
that lens in mind and your your
attitude this is a big part of
the literacy is you're having
this conversation, you know.
You know, why does gravity work
the way it works, and you can go
down a real rabbit hole and get
into very technical details
right? And some of those might
be wrong. And so the literacy
is. How do you go check to make
sure that the The answer you got
was accurate, and some of it may
be, in fact, you Google, right?
You look for factual sources. So
you need to know what to trust.
It also might be your own logic
and reasoning And this is, I
think a really important skill
that a I can help students learn
because it can be faulty right
that students we really need to
teach students.
The question its logic and
reasoning and by doing so fine
tune their own logic and
reasoning.
Um
So I think all of those are are
pieces of the puzzle.
And, um
Well, there's a lot more to say.
But I Yes, I will. I will leave
it there. Thank you. That's a
good starting point.
And then, um
What? I was really impressed
with the fact that the UMB and
every field of life
That's very powerful that the
question What does it mean to
think? Um, but my other question
is in light of the for water and
climate and everything and the
energy source that Cairo's here
in town is that don't use so
much water things has this.
A I campus produce that type of
research looking. How do we
address this? Uh, challenge We
have
In providing electricity. Excuse
me, Tera and representative
Garrett. So, um, yes. So there
has been even before a I like
lot lots of research in
materials design in energy. So
new designs for new chemical
reactions to store energy and
batteries, For example, maybe
lithium right. There's some
problems with with lithium
batteries both. So are there
other chemical reactions that
can store energy? Um, that is a
place where a I plays the same
sort of
But it does an antibiotics right
of Oh, look, we we know about
thousands, millions of different
compounds and their
interactions. Can we find
plausible cycles that that could
help this and it's the same kind
of question, though. Then, of
course, you've got to go through
all the safety and you've got
ready. It takes years and years
of development Once you have
those suggestions, Um, but I
think this is a place where a I
absolutely will accelerate the
use and development of greener
technologies. Um
The question is right how this
is the balance point, Right?
You're you're going to use
energy to do this?
It could be very much worth it.
You know, you might get million
fold returns on your
investments, right if you do
both wisely or you may, you
know, burn a lot of power and
lose a lot of water on a bed
that doesn't pan out and and how
to balance that, I think is a is
a good question. I think that
often in thinking about
environmental consequences are
tendency is to say we need to
hold back.
Right, but that can have really
negative consequences, right if
what we are holding back is is a
better green technology that can
replace, you know, burning of
fossil fuels. So, I, I think
this is again a place to tread
carefully and check that. You
know, we made this investment.
Give it enough time. Did this
investment actually result in
the thing that we thought it
would invest, it would would
happen allows some flexibility
there. I mean, most of these
things won't pan out, right? I
mean, that is the nature of
research is that most things
fail. Um, and a few things are
revolutionary change. And so
figuring out how to balance that
is, is the kind of thing
universities do and I think we
actually have a pretty good
track record, especially in
actually material design in the
end. Um, my colleagues do a lot
of great. Thank you, Madam
Chair.
And I talk about if we could go
back to portion very quickly. We
talked about it in the classroom
with Children. Um, but they are
being raised around the
technology.
And
In my experience in my own you
raised around the technology
have a more intuitive
Sense of how it can be used, and
we should definitely be teaching
them like, say, a I every day,
But there's still that kind of
intuitive sense how to approach
technology subject that kind of
just have that inherent kind of
uncanny valley ability that
adults don't have. So my
question.
It just really, What are your
thoughts on a I literacy for
Madam chair and thank you,
representative. So, um, great
question on on the youth side.
It is true that they have a much
more intuitive ability to use
these tools. That's not always
good right if we see how
Children use social media
It's they're they're intuitive
way they interact with it is not
necessarily good for them. Um,
adults do tend to have both a
fear of it. And an inability to
just, you know, pick up the
thing and make it work.
Um And this is a tricky piece.
Because there is some. There are
some things I have fear of,
right? We really do need people
to be wary of the deep fake
scams, For example, Um, On the
other hand, I think adults
actually could benefit from the
use of these tools, right? If if
a person can can use chatty BT
to find out or Gemini or llama
or whatever to find out like
what services are available for
me in a conversational way,
that's actually in easier to
interact with than, say, a
Google search that could be a
real benefit.
So I think one question And
then, of course, how do we have
access to educate adults? Right?
You do this in community
centers. Do you do this in after
hours? Classes like you know
adults are right. We We tend not
to go back to school, right? Um
so I think that one there needs
to be incentive that people need
to see some benefit some clear
benefit to to doing this, Um
and, uh, you know things as
simple as public service
announcements that play in
community centers and senior
centers and to warn people about
dangers.
But perhaps also like excite
people about opportunities right
to to use these, Um perhaps, you
know, government funded things.
P SAS tend to be, you know,
warning people to protect
themselves, and I think it's
warranted. Um
I do not have a particular
suggestion. I have. I'm not
aware of sort of a campaign to
do that in any particular state.
That might be a good question to
research have have people
actually engaged. Yes, thank
you, Doctor. Thank you, Madam
Chair and I. I wasn't suggesting
suggesting that you offer
solutions. I just kind of wanted
to know your thoughts. So a lot
of
Because I'm because there are,
um, you and out in the areas.
Lady.
And then we have these gaps
still in our statutes, and I'm
glad, um, Representative
Chandler kind of brought you
know what? What's the end goal,
But in the end for us to address
the lack of
It's almost like going back to
human traffic CS and when they
say, well, they didn't break a
law.
I'm
It when we do bills. We look at
steps are those best if if we
had to do
So thank you, Madam Chair for
the question. And I, um I think
that the, um
So these are yes. I tried to get
to three priorities and I got to
five plus three. So eight for
you,
Um I think that uh, yes, I would
say that a I literacy is
probably the most thing on the
important thing. Um, on the
positive side and and finding
ways to really engage the
public, I think literacy is not
enough but feeling like they and
and having them actually be part
of this kind of conversation
with the technology on the other
side. I think that the
transparency piece is as
important as the
Fake piece to get at the, uh,
the question that Senator Pinto
also asked. You know if people
are being harmed by the by this
technology, and they have no
idea that it's happening, and if
they know it's happening, But
they have no idea why. I think
that that is the that's the
situation that we really can
prevent by requiring
transparency in the use of
algorithms to make decisions,
and I think previously and I
think the the current bill that
that's drafted addresses this
from the perspective of
government activities that if
there's a government
That is engaged in in making a
decision about someone's life.
That it it needs This
transparency Um and
explainability, and some
analysis that it is, in fact,
equitable.
Um, but I also think in many of
the cases that matter to people
it is, you know, it's a private
employer that's using this tool.
Right there, and and there's
nothing in place that would say
that they need any kind, so I
think that is both a harder
problem. Um, maybe it makes
sense to take the first step in
in government transparency in
government decision making
tools, but I think it has to be
with the eye toward we really do
need to address. You know how
this plays out in lending and
housing decision Now it's still
I think wide open to allow the
use of these tools, which are a
shortcut for companies right to
make decisions.
Um, that really can have real
consequential harm to different
populations, and it will affect
different populations
differently. Right. So rural
populations, um people of color.
These are all going to be
population. I think that is sort
of of equal where they were
talking about the first
diversify our economy and
bringing in these these data
centers or call centers. But but
data centers but, um because of
electricity and the water right
now, that would be impossible,
But so I had to diversify, But
we have to find the right thing
to do is just not there yet, but
hopefully soon
Time during this next seven
months. And, um, just appreciate
you and thank you for coming
after a long flight from DC, I
we So appreciate you.
Thank you, Madam Chair. I want
to also extend my thank you to
Professor Moses. Uh, the handout
that she was, uh, referring to
con constantly. I got a 10
minutes to work. She finished it
and sent it while she was on the
plane.
Uh, so I she's probably heavily
caffeinated right now. Uh, but
thank you very much. I think
that was very useful for this
work plan.
OK, the work plan should will be
on this Manila. Uh, page.
The proposal. Three areas. Uh,
actually, uh, about four areas.
Artificial intelligence.
Uh, the progress of the build
out of, uh, high throughout the
state.
Uh,
Cyber security environment and
Both in the garden growing, uh,
demand for electric vehicles and
how to build it and allow that
to happen.
Deficit in both in home charging
or business, char.
Um
Within a I the reason that we
because
It's a huge topic and
I wanted to make sure that you
had the background to be able to
debate which areas you wanted to
focus on.
What I heard from there are
three
Area.
Broad categories that you could
look at one would be
How a I is used in research
applications, and this committee
has looked at many different
research programs, and you could
pursue that that might end up
being kind of a A river Delta
that just goes out forever
because everyone's using it for
their own particular research.
Program. Um another would be
How it's used in decision making
and provision of services.
That could be provisional.
And serve it and decision making
with regard to education.
Health care, mental health.
Uh,
Insurance so things but that's a
broad category.
Third broad category would be
the one that you just talked
about, which is research use.
Electricity, water, and I would
also say
Work for included in that.
So the if those are the main
three categories, my th my
original thought was that you
would narrow down on two or
three specific things.
Ah!
Within those categories and tell
me OK, go find the presenters to
tell those stories so that you
would not
What you need to do. Going into
the, uh
Obsession.
Uh, I think research
applications really is Professor
Moses was calling investment.
Uh, regulatory provision of
services. Should a. I chat GB TB
providing the the
And then resource use.
So, uh,
Portion of this madam chair is
for
You will to, uh, make proposals
of which categories and then
which subset you
I
Broadband.
Broadband.
Broadband is in.
Yeah, just a thorough,
But
I I'm just saying money from
these, you know.
They'll ask us for money for
something and we'll give them
easy.
Madam chair if I might recommend
Uh,
Or
Letter categories. BC and D on
the work plan, which are
broadband at cyber security and
demand, you know.
Electric vehicle infrastructure.
Uh, if you want to pull the
committee on whether
Those are three categories that
Makes sense and jerk back to
The probably more in the weeds
and difficult decision of how to
narrow down a. I
Is that and I and I did hear you
from various aspects of
broadband. You were moving on to
Artificial intelligence, but I
heard from
The, uh
To member was one
A emphasis on how to get
transparency for the current
uses. I mean the building. This
is basically inventory the uses
and figure out who's using them.
For what first step towards
transparency. And then what I
heard from Senator PTO Madam
chair was necessarily specific
to a I. It was more of
Had ideas legislation from a
couple of years ago.
One of them.
There is so much in each I
I caution the committee only
because there's a A I on the
agenda, it just grows and that
My arms around.
So
My thought was that you all
could say OK, we wanna get our
three discrete top three giant
categories. And then there are
big, uh, you could pick
You know, one part of
A I services and say, OK, we
wanna look at
Education services or mental
health pick one from resources.
You know you you could just a RE
doing that might be discreet.
But just I was trying to break
down what we heard into
Category grapple with
I don't know if I was healthy
investments that would look at
many will probably hear some of
that was those research
professors are gonna want to
tell you. This is what we're
using this for, but
If you wanna
Direct
The pres presentations. OK,
where do you need investment?
In a I to be able to and make
sure the president investment
made by the Legislature, Real
World Outcomes.
Professor, Um is that I
Thank you, Madam Chair. Sorry to
put you on the spot.
No worries. Wait. I have my
government relations person over
there. Throw things at me if I
say the wrong thing, Uh so I
think that the, um
Probably the investment that is
hardest for us to sustain is
actually an education.
So, uh, there is some role for
for supporting research and
supporting a vibrant sort of
You know, University Lab is
important, but, um
Re, you know, Faculty, we go
out. We get research grants and
things like that education just
a sustained educational program
that really serves. You know,
all of the both K through 12 and
university students in the
state. That's a pretty major
effort, right? We do not offer
you know, computer science or a
I literacy right now. Um, so I
think that would probably be the
the most obvious place where
state investment is important.
Um, on the research front, I
think it would be providing some
Or for other efforts, where the
majority of that money, you
know, for research efforts come
from university faculty getting
federal grants or, you know,
Department of Energy. Can. Um so
we we certainly could look at,
you know, specific sort of
targeted ways. It would catalyze
some of that and provide
You know?
The the the state as a partner
in that, um, but I think the
larger uh, yes, Ma'am. Jerry
strikes me that that might be
another one where we
Where this committee ends up
having a lot of overlap with LES
C, the general education budget
and how to invest in that this
committee is more a science and
tech
A. I tends to
As many, many science and tech
tends to cover both. I just, uh
point out that last year the
committee
Or
Again. I apologize, man. I'm
sure I hope I'm not too late on
this but one
Ma chair I. I do believe that
Uh, if you have more than four
focal points
You're probably
Oversight functions.
If likelihood, you know.
That clearly could be work plan.
But I think it's going. We'll do
I think, uh, well.
Me creating what you want to
focus on. I'm hearing a lot of
transparence, one of the
subcategories more than four
subcategories may be
transparency and
Uh,
Looking at and seeing if that's
enough, if it's not right, that
could be one of those three or
four. That would be a
So then you're left with
You know, provision of services
and and
It's kind of what I thought.
this presentation from Professor
Moses is going to be, but she
made it much broader and covered
more. Many more things than I
expected. We keep on hearing
from you, meaning the committee
has said people raise issues
about
A. I use decision making in
medical, uh, provisions or
mental health or housing or live
you might wanna pick one of
those, and then have
The third one be just
The overall resource use out
So I'm seeing a lot of nodding
of heads.
I. I think what I'm hearing
Madam Chair and see is a
Subcategories of
Transparency and inventory of
uses so that you kind of know
which sectors are are using, uh
in
criminal justice, you know?
If we had to go to the main
topics. Yeah, um
You health care.
And then I think there was a
fair amount of consensus of the
resource use of a I the demands
and what that's got, You know,
Energy water. You have a flyer
from the Moga. They made a big
pitch that they're expecting a
large demand.
So those would be three. You
might wanna add 1/4 1 as far as
we need to we, we as a committee
need to look at that. How do we
get kids in so that this is your
test? How do we get kids in? How
do we get excited? What do we
need to do? Because sports need
OK, so literacy?
Yeah, yeah, on kids, but
You're gonna get questions about
Adults as well. Yeah, I put
literacy
Yeah, Trying to get them
interested in anything was
tough, but I was trying to bring
in, so I decided to bring that
in, and I couldn't get them
interested. And it was just for
me. I thought it was a but, um
what? There's so many cool
things out there and we just and
maybe, you know, be able to take
out and say this is what's
happening. So you know for our
state and the kids and
Vehicle to grid.
Um
You know, charging station
design development chief.
A great technology that is
number four, OK?
Ma'am chair. I think that's a
full work plan, if you if that's
what you want to go with.
The, uh
OK, so on the back of your work
plan.
Is a
Proposed, uh, me. The dates are
not
Harden concrete yet, but they're
getting harder and harder this
year, particularly in election
year with a special session.
Hard to avoid.
Minimize we can't avoid. There
are
Before the special
we had 100 and eight committee
days to fit within 100 and 54
actual physical days, so there's
gonna be some overlap and that
got harder after the
announcement.
Uh, so
The proposal is especially in an
election year. Getting quorum
can be difficult as we move
along to try to keep more of the
meetings in central I 40 or I 25
cord or which is
I know.
There are pros and cons to that.
Uh, so it would be in the July
meeting would be at UN M.
The August meeting.
September. Santa Fe in October.
We, uh, final meeting
Where the labs had a thing.
I've talked with you. They are
very happy with these dates.
And
For the first time since I've
staffing this committee.
The proposal is to spend both
days in Socorro and not try to
make that a traveling committee
date.
And, uh,
I like that because E committee
members have come up to me and
complained about Oh, but they're
doing this exciting thing over
there. We didn't get to and
hopefully you all will get
enough time to actually
thoroughly enjoy the New Mexico.
They
Offered us to take
Take us to the robotics lab.
And to the, uh
Mythbusters. Explosions do that
in the past and make things a
little more
If you would like.
Yes, Yes, I understand.
I can make the request. If you,
uh, the committee would like to
go to
San make inquiry there that
brings up something that's on
the pink sheets.
Um
As Webcasting has become more
and more prevalent for
Committees.
A lot of the shut ins around the
state.
Have raised 88 concerns that a
lot of, uh
Committee meetings. So any
committee mean
Comment will have to provide for
Webcasting.
Uh,
Public comment as well.
That's not
Always
When, uh, committees have met at
that beautiful meeting.
So
For you, You and M Tao that's
inside in Taos.
We could never webcast out.
So, uh, because of the 3 to 4 ft
adobe walls.
We probably could meet, uh or
other committees can meet at UN
M.
TAS main campus, which is
outside of town, but the one in
town
We will not be allowed. Well, no
committee will be any sort.
At that site, because if we do
it for the goose, we gotta do it
for the gan.
OK?
OK, um, so just to confirm on
the A I portion we will
I will be tasked with finding
presentations to fill out the
idea of transparency and
inventory and
The proposed legislation.
Services health care, but it
might also literacy attached to
it. And then
Resources for a I
I. I left investment out. Uh,
but if you want, I think we have
enough. OK, I can. That can be a
filler that Nathan. When we go
to U and M, we'll make sure to
make have you and M make a
pitch. Yeah,
OK, so I
I
I don't know.
I believe there's a why doesn't
change this at all. Without
But it probably doesn't change.
Ma'am chair. I'll check to see
if there is one in San
Right?
Madam Chair members of the
committee. Thank you, Madam
Chair. I forgot one switching to
the screens, and we've changed
everything that's involved with
or
Technology for Webcasting.
And we even had
I ended up with three different,
uh, tutorials on how to make it
at work. We had a big one with
all the staff last year or
yesterday.
And for some reason, we can't
get webcasting out of the new
system in this
Room or in 307 today.
This happens with all
Changes of technology.
Uh, every time we've done it,
we've had a problem. I apologize
in advance for the any emails or
calls you get from constituents,
saying I tried and I, it was
just a blank screen.
I'm very frustrated because
there were a couple of people
that like Na Moga that wanted to
Tap into this one and tap into
